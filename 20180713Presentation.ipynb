{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing with Kronikare 13 July 2018\n",
    "## Agenda\n",
    "- [Demo on CascadedFCN](#CascadedFCN) 30 mins\n",
    "- [Dicussion and Q&A](#Dicussion) 15 mins\n",
    "- [Sprint Planning](#Sprint-Planning) 15 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CascadedFCN\n",
    "Paper suggest a noval approach to segment liver and lesions from CT and MRI images. <br>\n",
    "There are 3 main steps:\n",
    "1. Preprocessing (ref to figure3)\n",
    " - HU windowing for CT and N4Boas correction for MRI\n",
    " - Histogram Equalization\n",
    " - Augmentation (mirror, crop, elastic deformation, addition of noise)\n",
    "2. 2-cascaded FCN (ref to figure6)\n",
    " - First segments liver\n",
    " - Then segments the leisons\n",
    "3. Post processing\n",
    " - 3D Conditional Random Field\n",
    "\n",
    "![Preprocessing](Preprocessing_from_paper.png)\n",
    "\n",
    "![CascadedFCN](CascadedFCN_from_paper.png)\n",
    "\n",
    "## How we are doing it\n",
    "Since our images are RGB, we are not going to do the HU windowing/N4Bias Correction nor Histogram Equalization. <br>\n",
    "We are just using Augmentation by [Augmentor](http://augmentor.readthedocs.io/en/master/) because we find that the Off-the-shelf Augmentation by Tensorflow has some artifacts (Extrapolation of pixels which makes images look funny). We are employing:\n",
    "- Rotation and automatic Zoom\n",
    "- Zoom\n",
    "- Flipping Vertically and Horizontally\n",
    "- Shearing\n",
    "\n",
    "After doing the augmentation, we are going feed the UNet with the masks and images <br>\n",
    "Due to memory limitation, we are using the .flowfromdirectory method from the ImageDataGenerator Class which reads batches of images and masks pairs from disk into memory. However, the off-the-shelf onehotencoding has some memory problem too, so some time was spent to do the onehotencoding after reading in the images and masks per batch.<br>\n",
    "Below is an overview on how we are implementing the paper for our own use case\n",
    "![Howwearedoing](CascadedFCN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations\n",
    "[1] [CascaedFCN](arXiv:1702.05970) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renjie/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29a6904e347e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'metrics'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, UpSampling2D, MaxPooling2D, Dropout, Cropping2D, Input, merge\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from metrics import f1 as f1_score\n",
    "\n",
    "\n",
    "def UNet(filters_dims, activation='relu', kernel_initializer='glorot_uniform', padding='same'):\n",
    "    inputs = Input((480, 640, 3))\n",
    "    new_inputs = inputs\n",
    "    conv_layers = []\n",
    "    # Encoding Phase\n",
    "    for i in range(len(filters_dims) - 1):\n",
    "        conv = Conv2D(filters_dims[i], 3, activation=activation, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer)(new_inputs)\n",
    "        conv = Conv2D(filters_dims[i], 3, activation=activation, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer)(conv)\n",
    "        conv_layers.append(conv)\n",
    "        new_inputs = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "        # op = BatchNormalization()(op)\n",
    "\n",
    "    # middle phase\n",
    "    conv = Conv2D(filters_dims[-1], 3, activation=activation, padding=padding,\n",
    "                  kernel_initializer=kernel_initializer)(new_inputs)\n",
    "    conv = Conv2D(filters_dims[-1], 3, activation=activation, padding=padding,\n",
    "                  kernel_initializer=kernel_initializer)(conv)\n",
    "    new_inputs = Dropout(0.5)(conv)\n",
    "\n",
    "    filters_dims.reverse()\n",
    "    conv_layers.reverse()\n",
    "\n",
    "    # Decoding Phase\n",
    "    for i in range(1, len(filters_dims)):\n",
    "        up = Conv2D(filters_dims[i], 3, activation=activation, padding=padding,\n",
    "                    kernel_initializer=kernel_initializer)(UpSampling2D(size=(2, 2))(new_inputs))\n",
    "        concat = merge([conv_layers[i-1], up], mode='concat', concat_axis=3)\n",
    "        conv = Conv2D(filters_dims[i], 3, activation=activation, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer)(concat)\n",
    "        new_inputs = Conv2D(filters_dims[i], 3, activation=activation, padding=padding,\n",
    "                            kernel_initializer=kernel_initializer)(conv)\n",
    "    outputs = Conv2D(2, 1, activation='softmax', padding='same',\n",
    "                     kernel_initializer='glorot_uniform')(new_inputs)\n",
    "\n",
    "    model = Model(input=inputs, output=outputs, name='UNet')\n",
    "    model.compile(optimizer=Adam(lr=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'mse', f1_score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
